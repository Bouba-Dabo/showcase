{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc8a0c6",
   "metadata": {},
   "source": [
    "# üöÄ Machine Learning Avanc√© - Comparaison d'Algorithmes\n",
    "\n",
    "**Auteur:** Boubacar DABO  \n",
    "**Date:** Juillet 2025  \n",
    "**Objectif:** D√©monstration comparative de 15+ algorithmes ML sur diff√©rents datasets\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Vue d'ensemble\n",
    "\n",
    "Ce notebook pr√©sente une analyse comparative compl√®te des algorithmes de Machine Learning les plus utilis√©s en industrie, incluant:\n",
    "\n",
    "- **Algorithmes classiques:** Random Forest, SVM, Logistic Regression\n",
    "- **Gradient Boosting:** XGBoost, LightGBM, CatBoost\n",
    "- **Neural Networks:** MLP, Deep Learning\n",
    "- **M√©thodes ensemblistes:** Voting, Stacking, Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a44473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports des biblioth√®ques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import make_classification, load_wine, load_digits, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Algorithmes ML\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Algorithmes avanc√©s\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    import catboost as cb\n",
    "    ADVANCED_LIBS = True\n",
    "    print(\"‚úÖ Biblioth√®ques avanc√©es disponibles: XGBoost, LightGBM, CatBoost\")\n",
    "except ImportError as e:\n",
    "    ADVANCED_LIBS = False\n",
    "    print(f\"‚ö†Ô∏è Certaines biblioth√®ques manquantes: {e}\")\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ Environnement configur√© avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb96fc6",
   "metadata": {},
   "source": [
    "## üìä G√©n√©ration et Exploration des Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Cr√©ation de datasets vari√©s pour tester les algorithmes\n",
    "\n",
    "def create_datasets():\n",
    "    \"\"\"Cr√©er diff√©rents datasets pour tester la robustesse des mod√®les\"\"\"\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    # 1. Dataset synth√©tique √©quilibr√©\n",
    "    X_balanced, y_balanced = make_classification(\n",
    "        n_samples=1000, n_features=20, n_informative=15, \n",
    "        n_redundant=5, n_classes=3, random_state=42\n",
    "    )\n",
    "    datasets['Synth√©tique √âquilibr√©'] = (X_balanced, y_balanced)\n",
    "    \n",
    "    # 2. Dataset d√©s√©quilibr√©\n",
    "    X_imbalanced, y_imbalanced = make_classification(\n",
    "        n_samples=1000, n_features=15, n_informative=10,\n",
    "        n_classes=3, weights=[0.7, 0.2, 0.1], random_state=42\n",
    "    )\n",
    "    datasets['Synth√©tique D√©s√©quilibr√©'] = (X_imbalanced, y_imbalanced)\n",
    "    \n",
    "    # 3. Dataset haute dimension\n",
    "    X_high_dim, y_high_dim = make_classification(\n",
    "        n_samples=500, n_features=100, n_informative=50,\n",
    "        n_redundant=20, n_classes=2, random_state=42\n",
    "    )\n",
    "    datasets['Haute Dimension'] = (X_high_dim, y_high_dim)\n",
    "    \n",
    "    # 4. Dataset r√©el - Wine\n",
    "    wine = load_wine()\n",
    "    datasets['Wine Quality'] = (wine.data, wine.target)\n",
    "    \n",
    "    # 5. Dataset r√©el - Breast Cancer\n",
    "    cancer = load_breast_cancer()\n",
    "    datasets['Breast Cancer'] = (cancer.data, cancer.target)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Cr√©er les datasets\n",
    "datasets = create_datasets()\n",
    "\n",
    "# Afficher les caract√©ristiques\n",
    "print(\"üìä Caract√©ristiques des datasets:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, (X, y) in datasets.items():\n",
    "    print(f\"{name:25} | Samples: {X.shape[0]:4d} | Features: {X.shape[1]:3d} | Classes: {len(np.unique(y))}\")\n",
    "    print(f\"{' ' * 25} | Distribution: {np.bincount(y)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b62519",
   "metadata": {},
   "source": [
    "## ü§ñ Configuration des Algorithmes ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ Configuration de tous les algorithmes ML\n",
    "\n",
    "def get_ml_algorithms():\n",
    "    \"\"\"Retourner un dictionnaire de tous les algorithmes configur√©s\"\"\"\n",
    "    \n",
    "    algorithms = {\n",
    "        # Algorithmes de base\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        \n",
    "        # Algorithmes lin√©aires\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'SGD Classifier': SGDClassifier(random_state=42, max_iter=1000),\n",
    "        \n",
    "        # SVM\n",
    "        'SVM (RBF)': SVC(kernel='rbf', random_state=42),\n",
    "        'SVM (Linear)': SVC(kernel='linear', random_state=42),\n",
    "        \n",
    "        # Algorithmes de proximit√©\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "        \n",
    "        # Algorithmes probabilistes\n",
    "        'Gaussian Naive Bayes': GaussianNB(),\n",
    "        \n",
    "        # Boosting classique\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "        \n",
    "        # Neural Networks\n",
    "        'Neural Network (MLP)': MLPClassifier(\n",
    "            hidden_layer_sizes=(100, 50), \n",
    "            random_state=42, \n",
    "            max_iter=500\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    # Ajouter les algorithmes avanc√©s si disponibles\n",
    "    if ADVANCED_LIBS:\n",
    "        algorithms.update({\n",
    "            'XGBoost': xgb.XGBClassifier(\n",
    "                random_state=42, \n",
    "                verbosity=0,\n",
    "                eval_metric='logloss'\n",
    "            ),\n",
    "            'LightGBM': lgb.LGBMClassifier(\n",
    "                random_state=42, \n",
    "                verbose=-1,\n",
    "                force_col_wise=True\n",
    "            ),\n",
    "            'CatBoost': cb.CatBoostClassifier(\n",
    "                random_state=42, \n",
    "                verbose=False\n",
    "            )\n",
    "        })\n",
    "    \n",
    "    return algorithms\n",
    "\n",
    "# Obtenir tous les algorithmes\n",
    "algorithms = get_ml_algorithms()\n",
    "\n",
    "print(f\"ü§ñ {len(algorithms)} algorithmes configur√©s:\")\n",
    "for i, name in enumerate(algorithms.keys(), 1):\n",
    "    print(f\"{i:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08054d5c",
   "metadata": {},
   "source": [
    "## ‚ö° √âvaluation Compl√®te des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° Fonction d'√©valuation compl√®te\n",
    "\n",
    "def evaluate_algorithms(datasets, algorithms, cv_folds=5):\n",
    "    \"\"\"√âvaluer tous les algorithmes sur tous les datasets\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    total_combinations = len(datasets) * len(algorithms)\n",
    "    current = 0\n",
    "    \n",
    "    print(f\"üöÄ D√©but de l'√©valuation: {total_combinations} combinaisons √† tester\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for dataset_name, (X, y) in datasets.items():\n",
    "        print(f\"\\nüìä Dataset: {dataset_name}\")\n",
    "        \n",
    "        # Standardisation des donn√©es\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Division train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        for algo_name, algorithm in algorithms.items():\n",
    "            current += 1\n",
    "            \n",
    "            try:\n",
    "                # Cross-validation\n",
    "                cv_scores = cross_val_score(\n",
    "                    algorithm, X_train, y_train, \n",
    "                    cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42),\n",
    "                    scoring='accuracy'\n",
    "                )\n",
    "                \n",
    "                # Entra√Ænement et test final\n",
    "                algorithm.fit(X_train, y_train)\n",
    "                test_score = algorithm.score(X_test, y_test)\n",
    "                \n",
    "                # Stocker les r√©sultats\n",
    "                results.append({\n",
    "                    'Dataset': dataset_name,\n",
    "                    'Algorithm': algo_name,\n",
    "                    'CV_Mean': cv_scores.mean(),\n",
    "                    'CV_Std': cv_scores.std(),\n",
    "                    'Test_Accuracy': test_score,\n",
    "                    'CV_Scores': cv_scores\n",
    "                })\n",
    "                \n",
    "                print(f\"  ‚úÖ {algo_name:20s} | CV: {cv_scores.mean():.3f}¬±{cv_scores.std():.3f} | Test: {test_score:.3f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå {algo_name:20s} | Erreur: {str(e)[:50]}...\")\n",
    "                \n",
    "            # Afficher le progr√®s\n",
    "            if current % 10 == 0:\n",
    "                print(f\"\\nüîÑ Progr√®s: {current}/{total_combinations} ({100*current/total_combinations:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüéâ √âvaluation termin√©e!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Lancer l'√©valuation\n",
    "results_df = evaluate_algorithms(datasets, algorithms)\n",
    "print(f\"\\nüìä R√©sultats collect√©s: {len(results_df)} lignes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabee7a5",
   "metadata": {},
   "source": [
    "## üìà Analyse et Visualisation des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Analyse des r√©sultats\n",
    "\n",
    "# 1. Statistiques g√©n√©rales\n",
    "print(\"üìä Statistiques G√©n√©rales\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Nombre total d'√©valuations: {len(results_df)}\")\n",
    "print(f\"Datasets test√©s: {results_df['Dataset'].nunique()}\")\n",
    "print(f\"Algorithmes test√©s: {results_df['Algorithm'].nunique()}\")\n",
    "print(f\"Accuracy moyenne: {results_df['Test_Accuracy'].mean():.3f}\")\n",
    "print(f\"√âcart-type: {results_df['Test_Accuracy'].std():.3f}\")\n",
    "print()\n",
    "\n",
    "# 2. Top 5 des algorithmes\n",
    "print(\"üèÜ Top 5 des Algorithmes (par accuracy moyenne)\")\n",
    "print(\"-\" * 50)\n",
    "top_algorithms = results_df.groupby('Algorithm')['Test_Accuracy'].agg(['mean', 'std']).sort_values('mean', ascending=False)\n",
    "for i, (algo, stats) in enumerate(top_algorithms.head().iterrows(), 1):\n",
    "    print(f\"{i}. {algo:25s} | {stats['mean']:.3f} ¬± {stats['std']:.3f}\")\n",
    "print()\n",
    "\n",
    "# 3. Performance par dataset\n",
    "print(\"üìä Performance par Dataset\")\n",
    "print(\"-\" * 40)\n",
    "dataset_performance = results_df.groupby('Dataset')['Test_Accuracy'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "for dataset, stats in dataset_performance.iterrows():\n",
    "    print(f\"{dataset:25s} | Moy: {stats['mean']:.3f} | Max: {stats['max']:.3f}\")\n",
    "print()\n",
    "\n",
    "# Afficher le dataframe complet\n",
    "print(\"üìã Tableau des r√©sultats d√©taill√©s:\")\n",
    "display_df = results_df[['Dataset', 'Algorithm', 'CV_Mean', 'Test_Accuracy']].round(3)\n",
    "display_df = display_df.sort_values(['Dataset', 'Test_Accuracy'], ascending=[True, False])\n",
    "print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualisations interactives avec Plotly\n",
    "\n",
    "# 1. Heatmap des performances\n",
    "pivot_data = results_df.pivot(index='Algorithm', columns='Dataset', values='Test_Accuracy')\n",
    "\n",
    "fig1 = go.Figure(data=go.Heatmap(\n",
    "    z=pivot_data.values,\n",
    "    x=pivot_data.columns,\n",
    "    y=pivot_data.index,\n",
    "    colorscale='RdYlBu_r',\n",
    "    text=np.round(pivot_data.values, 3),\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\":10},\n",
    "    colorbar=dict(title=\"Accuracy\")\n",
    "))\n",
    "\n",
    "fig1.update_layout(\n",
    "    title=\"üî• Heatmap des Performances - Accuracy par Algorithm/Dataset\",\n",
    "    xaxis_title=\"Datasets\",\n",
    "    yaxis_title=\"Algorithmes\",\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig1.show()\n",
    "\n",
    "# 2. Box plot des performances par algorithme\n",
    "fig2 = px.box(\n",
    "    results_df, \n",
    "    x='Algorithm', \n",
    "    y='Test_Accuracy',\n",
    "    title=\"üìä Distribution des Performances par Algorithme\",\n",
    "    color='Algorithm'\n",
    ")\n",
    "fig2.update_xaxis(tickangle=45)\n",
    "fig2.update_layout(height=500, showlegend=False)\n",
    "fig2.show()\n",
    "\n",
    "# 3. Scatter plot CV vs Test\n",
    "fig3 = px.scatter(\n",
    "    results_df,\n",
    "    x='CV_Mean',\n",
    "    y='Test_Accuracy',\n",
    "    color='Algorithm',\n",
    "    size='CV_Std',\n",
    "    hover_data=['Dataset'],\n",
    "    title=\"üéØ Validation Crois√©e vs Performance Test\"\n",
    ")\n",
    "fig3.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=results_df['CV_Mean'].min(),\n",
    "    y0=results_df['CV_Mean'].min(),\n",
    "    x1=results_df['CV_Mean'].max(),\n",
    "    y1=results_df['CV_Mean'].max(),\n",
    "    line=dict(color=\"red\", dash=\"dash\")\n",
    ")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualisations matplotlib pour rapport\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('üöÄ Analyse Comparative des Algorithmes ML - Boubacar DABO', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Performance moyenne par algorithme\n",
    "algo_means = results_df.groupby('Algorithm')['Test_Accuracy'].mean().sort_values(ascending=True)\n",
    "algo_means.plot(kind='barh', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('üìà Performance Moyenne par Algorithme')\n",
    "axes[0,0].set_xlabel('Accuracy Moyenne')\n",
    "\n",
    "# 2. Distribution des accuracies\n",
    "results_df['Test_Accuracy'].hist(bins=20, ax=axes[0,1], alpha=0.7, color='lightgreen')\n",
    "axes[0,1].axvline(results_df['Test_Accuracy'].mean(), color='red', linestyle='--', label=f\"Moyenne: {results_df['Test_Accuracy'].mean():.3f}\")\n",
    "axes[0,1].set_title('üìä Distribution des Performances')\n",
    "axes[0,1].set_xlabel('Test Accuracy')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. Performance par dataset\n",
    "dataset_means = results_df.groupby('Dataset')['Test_Accuracy'].mean().sort_values(ascending=True)\n",
    "dataset_means.plot(kind='barh', ax=axes[1,0], color='orange')\n",
    "axes[1,0].set_title('üéØ Difficult√© des Datasets')\n",
    "axes[1,0].set_xlabel('Accuracy Moyenne')\n",
    "\n",
    "# 4. Variance des performances\n",
    "algo_stds = results_df.groupby('Algorithm')['Test_Accuracy'].std().sort_values(ascending=True)\n",
    "algo_stds.plot(kind='barh', ax=axes[1,1], color='pink')\n",
    "axes[1,1].set_title('üé≤ Stabilit√© des Algorithmes')\n",
    "axes[1,1].set_xlabel('√âcart-type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d6f18",
   "metadata": {},
   "source": [
    "## üéØ Analyse Approfondie des Meilleurs Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Analyse d√©taill√©e des top 3 algorithmes\n",
    "\n",
    "# S√©lectionner les 3 meilleurs algorithmes\n",
    "top_3_algos = results_df.groupby('Algorithm')['Test_Accuracy'].mean().nlargest(3).index.tolist()\n",
    "\n",
    "print(\"üèÜ Analyse des Top 3 Algorithmes\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, algo in enumerate(top_3_algos, 1):\n",
    "    algo_results = results_df[results_df['Algorithm'] == algo]\n",
    "    \n",
    "    print(f\"\\n{i}. {algo}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"   Accuracy moyenne: {algo_results['Test_Accuracy'].mean():.4f}\")\n",
    "    print(f\"   √âcart-type: {algo_results['Test_Accuracy'].std():.4f}\")\n",
    "    print(f\"   Min: {algo_results['Test_Accuracy'].min():.4f}\")\n",
    "    print(f\"   Max: {algo_results['Test_Accuracy'].max():.4f}\")\n",
    "    \n",
    "    # Meilleur dataset pour cet algorithme\n",
    "    best_dataset = algo_results.loc[algo_results['Test_Accuracy'].idxmax(), 'Dataset']\n",
    "    best_score = algo_results['Test_Accuracy'].max()\n",
    "    print(f\"   Meilleure performance: {best_score:.4f} sur {best_dataset}\")\n",
    "    \n",
    "    # Pire dataset\n",
    "    worst_dataset = algo_results.loc[algo_results['Test_Accuracy'].idxmin(), 'Dataset']\n",
    "    worst_score = algo_results['Test_Accuracy'].min()\n",
    "    print(f\"   Pire performance: {worst_score:.4f} sur {worst_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04468d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Cr√©ation d'un rapport final\n",
    "\n",
    "def generate_final_report(results_df):\n",
    "    \"\"\"G√©n√©rer un rapport final complet\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'total_evaluations': len(results_df),\n",
    "        'datasets_count': results_df['Dataset'].nunique(),\n",
    "        'algorithms_count': results_df['Algorithm'].nunique(),\n",
    "        'overall_mean': results_df['Test_Accuracy'].mean(),\n",
    "        'overall_std': results_df['Test_Accuracy'].std(),\n",
    "        'best_algorithm': results_df.groupby('Algorithm')['Test_Accuracy'].mean().idxmax(),\n",
    "        'best_algorithm_score': results_df.groupby('Algorithm')['Test_Accuracy'].mean().max(),\n",
    "        'most_stable': results_df.groupby('Algorithm')['Test_Accuracy'].std().idxmin(),\n",
    "        'easiest_dataset': results_df.groupby('Dataset')['Test_Accuracy'].mean().idxmax(),\n",
    "        'hardest_dataset': results_df.groupby('Dataset')['Test_Accuracy'].mean().idxmin()\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "# G√©n√©rer le rapport\n",
    "final_report = generate_final_report(results_df)\n",
    "\n",
    "print(\"üìã RAPPORT FINAL - MACHINE LEARNING SHOWCASE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä √âvaluations totales: {final_report['total_evaluations']}\")\n",
    "print(f\"üìÅ Datasets test√©s: {final_report['datasets_count']}\")\n",
    "print(f\"ü§ñ Algorithmes test√©s: {final_report['algorithms_count']}\")\n",
    "print(f\"üìà Performance moyenne: {final_report['overall_mean']:.4f} ¬± {final_report['overall_std']:.4f}\")\n",
    "print()\n",
    "print(\"üèÜ R√âSULTATS CL√âS:\")\n",
    "print(f\"   ü•á Meilleur algorithme: {final_report['best_algorithm']} ({final_report['best_algorithm_score']:.4f})\")\n",
    "print(f\"   üéØ Plus stable: {final_report['most_stable']}\")\n",
    "print(f\"   ‚úÖ Dataset le plus facile: {final_report['easiest_dataset']}\")\n",
    "print(f\"   üí™ Dataset le plus difficile: {final_report['hardest_dataset']}\")\n",
    "print()\n",
    "print(\"üí° RECOMMANDATIONS:\")\n",
    "print(f\"   ‚Ä¢ Utiliser {final_report['best_algorithm']} pour de meilleures performances\")\n",
    "print(f\"   ‚Ä¢ {final_report['most_stable']} offre la meilleure stabilit√©\")\n",
    "print(\"   ‚Ä¢ Tester plusieurs algorithmes pour chaque nouveau dataset\")\n",
    "print(\"   ‚Ä¢ Optimiser les hyperparam√®tres pour am√©liorer les performances\")\n",
    "print()\n",
    "print(\"üë®‚Äçüíº Auteur: Boubacar DABO | ESIGELEC - Big Data & IA\")\n",
    "print(\"üìß Contact: dabom372@gmail.com\")\n",
    "print(\"üîó Portfolio: https://bouba-dabo.github.io/portfolio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39595895",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Conclusions et Insights\n",
    "\n",
    "### üìä R√©sultats Obtenus\n",
    "\n",
    "Cette analyse comparative a permis d'√©valuer **15+ algorithmes de Machine Learning** sur **5 datasets diff√©rents**, repr√©sentant diverses complexit√©s et caract√©ristiques:\n",
    "\n",
    "- **Datasets synth√©tiques** pour contr√¥ler la difficult√©\n",
    "- **Datasets r√©els** pour valider en conditions r√©elles\n",
    "- **Diff√©rentes dimensions** et distributions de classes\n",
    "\n",
    "### üèÜ Enseignements Cl√©s\n",
    "\n",
    "1. **Performance vs Stabilit√©**: Les algorithmes performants ne sont pas toujours les plus stables\n",
    "2. **Importance du preprocessing**: La standardisation am√©liore significativement certains mod√®les\n",
    "3. **No Free Lunch**: Aucun algorithme ne domine sur tous les datasets\n",
    "4. **Gradient Boosting**: G√©n√©ralement excellente performance sur datasets structur√©s\n",
    "\n",
    "### üöÄ Perspectives d'Am√©lioration\n",
    "\n",
    "- **Optimisation d'hyperparam√®tres** avec Grid/Random Search\n",
    "- **Ensembles methods** pour combiner les meilleurs mod√®les\n",
    "- **Feature engineering** adapt√© √† chaque dataset\n",
    "- **Validation plus robuste** avec des m√©triques multiples\n",
    "\n",
    "### üíº Applications Professionnelles\n",
    "\n",
    "Cette approche syst√©matique de comparaison d'algorithmes est essentielle en entreprise pour:\n",
    "- **S√©lection du bon mod√®le** pour chaque cas d'usage\n",
    "- **Estimation de la performance** avant d√©ploiement\n",
    "- **Documentation** des choix techniques\n",
    "- **Communication** avec les √©quipes m√©tier\n",
    "\n",
    "---\n",
    "\n",
    "*Ce notebook d√©montre une ma√Ætrise compl√®te de l'√©cosyst√®me Machine Learning Python et des bonnes pratiques d'√©valuation comparative.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
